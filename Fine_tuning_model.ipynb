{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d28fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, RobertaTokenizer, RobertaModel\n",
    "import time\n",
    "import argparse\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from train import BERT_Arch\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='roberta-base', help='set model type')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='set batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='set number of epochs')\n",
    "args = parser.parse_args()\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "results_file_path = \"result.txt\"\n",
    "# Load Dataset\n",
    "df = pd.read_csv(\"spamdata_v2.csv\")\n",
    "df.head()\n",
    "df.shape\n",
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51818540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use temp_text and temp_labels to create validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_labels)\n",
    "def bert():\n",
    "    if args.model == 'roberta-base':\n",
    "        bert = RobertaModel.from_pretrained(args.model)\n",
    "    else:\n",
    "        bert = AutoModel.from_pretrained(args.model)\n",
    "    # Freeze BERT Parameters\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = False\n",
    "    return bert\n",
    "def load_model():\n",
    "    # Import BERT Model and BERT Tokenizer\n",
    "    # import BERT-base pretrained model\n",
    "    # Load the BERT tokenizer\n",
    "    if args.model == 'roberta-base':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(args.model)\n",
    "    else:\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(args.model)\n",
    "    # sample data\n",
    "    text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
    "    # encode text\n",
    "    sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # output\n",
    "    print(sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a980b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Tokenization\n",
    "    # get length of all the messages in the train set\n",
    "    seq_len = [len(i.split()) for i in train_text]\n",
    "    pd.Series(seq_len).hist(bins=30)\n",
    "    max_seq_len = 25\n",
    "    # tokenize and encode sequences in the training set\n",
    "    tokens_train = tokenizer.batch_encode_plus(\n",
    "        train_text.tolist(),\n",
    "        max_length=max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tokenize and encode sequences in the validation set\n",
    "    tokens_val = tokenizer.batch_encode_plus(\n",
    "        val_text.tolist(),\n",
    "        max_length=max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dacc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tokenize and encode sequences in the test set\n",
    "    tokens_test = tokenizer.batch_encode_plus(\n",
    "        test_text.tolist(),\n",
    "        max_length=max_seq_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "    # Convert Integer Sequences to Tensors\n",
    "    # for train set\n",
    "    train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "    train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "    train_y = torch.tensor(train_labels.tolist())\n",
    "    # for validation set\n",
    "    val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "    val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "    val_y = torch.tensor(val_labels.tolist())\n",
    "    # for test set\n",
    "    test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "    test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "    test_y = torch.tensor(test_labels.tolist())\n",
    "    return [train_seq, train_mask, train_y, val_seq, val_mask, val_y, test_seq, test_mask, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "train_test_result = load_model()\n",
    "train_data = TensorDataset(train_test_result[0], train_test_result[1], train_test_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "val_data = TensorDataset(train_test_result[3], train_test_result[4], train_test_result[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f871b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4734f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5467eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Class Weights\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n",
    "print(class_wts)\n",
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63877e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tune BERT\n",
    "# function to train the model\n",
    "def train():\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a87b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    total_loss, total_accuracy = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # empty list to save model predictions\n",
    "    total_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9866e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c461e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c526924",
   "metadata": {},
   "outputs": [],
   "source": [
    "        sent_id, mask, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29923b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b16add",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # update parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88860f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # append the model predictions\n",
    "        total_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a27a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # deactivate dropout layers\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    total_loss, total_accuracy = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # empty list to save the model predictions\n",
    "    total_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be068f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8315667",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc813ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        sent_id, mask, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # deactivate autograd\n",
    "        with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2348e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # model predictions\n",
    "            preds = model(sent_id, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee97f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "            total_loss = total_loss + loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1108921",
   "metadata": {},
   "outputs": [],
   "source": [
    "            preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1674f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "            total_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa663ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Model Training\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb77536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "import os\n",
    "path = os.path.join(\"saved_\"+args.model+\".pt\")\n",
    "# for each epoch\n",
    "for epoch in range(epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f84bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # train model\n",
    "    train_loss, _ = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # evaluate model\n",
    "    valid_loss, _ = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        #torch.save(model.state_dict(), 'saved_weights_cased.pt')\n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828af129",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Saved Model\n",
    "#load weights of best model\n",
    "#bert = AutoModel.from_pretrained(args.model)\n",
    "# Load the BERT tokenizer\n",
    "#tokenizer = BertTokenizerFast.from_pretrained(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcee8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'saved_weights_cased.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Get Predictions for Test Data\n",
    "with torch.no_grad():\n",
    "    preds = model(train_test_result[6].to(device), train_test_result[7].to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # model's performance\n",
    "preds = np.argmax(preds, axis=1)\n",
    "result = classification_report(train_test_result[8], preds)\n",
    "    # confusion matrix\n",
    "pd.crosstab(train_test_result[8], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file_path, 'a') as file:\n",
    "    file.write(\"Model, Test accuracy\\n\")\n",
    "    file.write(f\"{args.model}, {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
